from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import pandas as pd
import time

# Configuration
SHAREPOINT_URL = "https://yourcompany.sharepoint.com/sites/yoursite/SitePages/YourPage.aspx"
USERNAME = "your.email@company.com"
PASSWORD = "yourpassword"  # Only use if not using SSO

def extract_sharepoint_with_selenium():
    driver = webdriver.Chrome()  # Requires ChromeDriver
    try:
        # Open SharePoint page (will use existing browser session if logged in)
        driver.get(SHAREPOINT_URL)
        
        # If login page appears, enter credentials
        try:
            username_field = driver.find_element(By.ID, "i0116")
            username_field.send_keys(USERNAME)
            driver.find_element(By.ID, "idSIButton9").click()
            time.sleep(2)
            
            password_field = driver.find_element(By.ID, "i0118")
            password_field.send_keys(PASSWORD)
            driver.find_element(By.ID, "idSIButton9").click()
            time.sleep(2)
            
            # Click "Stay signed in" if appears
            try:
                driver.find_element(By.ID, "idSIButton9").click()
                time.sleep(2)
            except:
                pass
        except:
            pass  # Already logged in
        
        # Wait for page to load
        time.sleep(5)
        
        # Extract page content
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # Extract tables (example)
        tables = []
        for table in soup.find_all('table'):
            df = pd.read_html(str(table))[0]
            tables.append(df)
            print(f"Found table with shape: {df.shape}")
        
        return tables
        
    finally:
        driver.quit()

# Usage
tables = extract_sharepoint_with_selenium()
for i, table in enumerate(tables, 1):
    table.to_excel(f"table_{i}.xlsx", index=False)
